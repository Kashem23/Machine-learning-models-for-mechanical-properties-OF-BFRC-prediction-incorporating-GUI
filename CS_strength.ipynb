{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCbEDO7Irq5F"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "sns.set(style=\"ticks\")\n",
        "#sns.set(style=\"whitegrid\", color_codes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWNDJ7nQrq5I"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('BFRC_CS.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "NpWQpxxorq5I",
        "outputId": "d424f3dd-0ed7-4509-aef8-8e863895ddf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(270, 11)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qQ9amARrq5J",
        "outputId": "505265e1-847f-40e3-d4a0-5fc8279a0ddc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement (kg/m³)</th>\n",
              "      <th>Fly ash (kg/m³)</th>\n",
              "      <th>Silica fume (kg/m³)</th>\n",
              "      <th>Coarse aggregate (kg/m³)</th>\n",
              "      <th>Fine aggregate (kg/m³)</th>\n",
              "      <th>Water (kg/m³)</th>\n",
              "      <th>Water reducing agent (kg/m³)</th>\n",
              "      <th>Fiber diameter (mm)</th>\n",
              "      <th>Fiber length (mm)</th>\n",
              "      <th>Fiber content (%)</th>\n",
              "      <th>Compressive strength (Mpa)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>270.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>400.675740</td>\n",
              "      <td>45.838193</td>\n",
              "      <td>13.612376</td>\n",
              "      <td>1077.088824</td>\n",
              "      <td>704.099177</td>\n",
              "      <td>175.676276</td>\n",
              "      <td>2.943329</td>\n",
              "      <td>0.015793</td>\n",
              "      <td>16.594462</td>\n",
              "      <td>0.125893</td>\n",
              "      <td>49.260605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>79.128978</td>\n",
              "      <td>56.696253</td>\n",
              "      <td>29.522911</td>\n",
              "      <td>186.438422</td>\n",
              "      <td>118.030548</td>\n",
              "      <td>32.874507</td>\n",
              "      <td>1.958920</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>5.990241</td>\n",
              "      <td>0.122632</td>\n",
              "      <td>12.051573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>75.785344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>176.570677</td>\n",
              "      <td>108.673517</td>\n",
              "      <td>30.845379</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001848</td>\n",
              "      <td>5.920463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>989.750000</td>\n",
              "      <td>613.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>1.080000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>41.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>402.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>689.600000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>3.360000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>48.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>450.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1181.300000</td>\n",
              "      <td>789.250000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>0.017300</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>59.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>613.330000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>1540.000000</td>\n",
              "      <td>1193.660000</td>\n",
              "      <td>301.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.021000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>69.900000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Cement (kg/m³)  Fly ash (kg/m³)  Silica fume (kg/m³)  \\\n",
              "count      270.000000       270.000000           270.000000   \n",
              "mean       400.675740        45.838193            13.612376   \n",
              "std         79.128978        56.696253            29.522911   \n",
              "min         75.785344         0.000000             0.000000   \n",
              "25%        350.000000         0.000000             0.000000   \n",
              "50%        402.000000         0.000000             0.000000   \n",
              "75%        450.000000        87.000000             0.000000   \n",
              "max        613.330000       168.000000           126.000000   \n",
              "\n",
              "       Coarse aggregate (kg/m³)  Fine aggregate (kg/m³)  Water (kg/m³)  \\\n",
              "count                270.000000              270.000000     270.000000   \n",
              "mean                1077.088824              704.099177     175.676276   \n",
              "std                  186.438422              118.030548      32.874507   \n",
              "min                  176.570677              108.673517      30.845379   \n",
              "25%                  989.750000              613.000000     160.000000   \n",
              "50%                 1125.000000              689.600000     175.000000   \n",
              "75%                 1181.300000              789.250000     185.000000   \n",
              "max                 1540.000000             1193.660000     301.000000   \n",
              "\n",
              "       Water reducing agent (kg/m³)  Fiber diameter (mm)  Fiber length (mm)  \\\n",
              "count                    270.000000           270.000000         270.000000   \n",
              "mean                       2.943329             0.015793          16.594462   \n",
              "std                        1.958920             0.002053           5.990241   \n",
              "min                        0.000000             0.001848           5.920463   \n",
              "25%                        1.080000             0.015000          12.000000   \n",
              "50%                        3.360000             0.015000          18.000000   \n",
              "75%                        4.200000             0.017300          20.000000   \n",
              "max                        8.000000             0.021000          30.000000   \n",
              "\n",
              "       Fiber content (%)  Compressive strength (Mpa)  \n",
              "count         270.000000                  270.000000  \n",
              "mean            0.125893                   49.260605  \n",
              "std             0.122632                   12.051573  \n",
              "min             0.000000                    0.000000  \n",
              "25%             0.050000                   41.625000  \n",
              "50%             0.100000                   48.460000  \n",
              "75%             0.160000                   59.200000  \n",
              "max             0.730000                   69.900000  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JExijezZrq5K",
        "outputId": "61b8c736-a637-4b3b-9449-7f2e3638afcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(270, 10)\n",
            "(270,)\n"
          ]
        }
      ],
      "source": [
        "# split into input (X) and output (Y) variables\n",
        "X = data.drop(['Compressive strength (Mpa)'], axis =1)\n",
        "Y = data['Compressive strength (Mpa)']\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rmndv0Qrq5L"
      },
      "outputs": [],
      "source": [
        "# randomly spliting the database into training-testing sets as 70%-30%\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
        "\n",
        "# normalizing the data sets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhBQ-ZDprq5L",
        "outputId": "2bead461-8723-4471-d75b-381cd2f28e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (189, 10)\n",
            "y_train shape: (189,)\n",
            "X_test shape: (81, 10)\n",
            "y_test shape: (81,)\n"
          ]
        }
      ],
      "source": [
        "# Print the shapes of the train and test sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at9R4v1prq5L"
      },
      "source": [
        "Different machine learning (ML) models are adopted below to predict the shear strength of concrete-filled steel tubes (CFSTs). The performances of these ML models are evaluated and compared with each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owkIzHbrrq5n"
      },
      "source": [
        "# Gradient Boosting Regression Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8hsOnfirq5n",
        "outputId": "86e574b6-f9b9-48ff-f12b-f352d8ff1234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 60}\n",
            "0.9873392600304229\n",
            "0.8489978451197223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "80 fits failed out of a total of 2480.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\kulsu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\kulsu\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
            "    self._check_params()\n",
            "  File \"C:\\Users\\kulsu\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 269, in _check_params\n",
            "    raise ValueError(\n",
            "ValueError: n_estimators must be greater than 0 but was 0\n",
            "\n",
            "One or more of the test scores are non-finite: [       nan 0.33826616 0.51486001 0.60960365 0.65859513 0.68713645\n",
            " 0.70537874 0.72128006 0.73240282 0.73892659 0.74401574 0.74732524\n",
            " 0.75001294 0.7522131  0.75327326 0.75411681 0.75469447 0.75550584\n",
            " 0.75639062 0.75773378 0.75916413 0.76016532 0.75989967 0.76003765\n",
            " 0.7599053  0.75980234 0.76036723 0.76093818 0.76125905 0.76140715\n",
            " 0.76112335        nan 0.38941015 0.57088161 0.6505325  0.69309846\n",
            " 0.71358632 0.72029851 0.72303794 0.72183458 0.72247749 0.7247168\n",
            " 0.72633644 0.72719899 0.72714982 0.72795197 0.72931579 0.73093701\n",
            " 0.73175038 0.73279948 0.73312242 0.73373934 0.73421453 0.73458636\n",
            " 0.73481072 0.73507439 0.73534528 0.73559084 0.73579472 0.73560259\n",
            " 0.73542207 0.73546874        nan 0.41803485 0.61020916 0.69136503\n",
            " 0.7257563  0.73651542 0.73864982 0.74178117 0.74560361 0.74724151\n",
            " 0.74776131 0.74750312 0.74922803 0.74994731 0.75028701 0.75074548\n",
            " 0.75094877 0.75102229 0.75133089 0.75155594 0.75159489 0.75160229\n",
            " 0.75175578 0.75185086 0.75188904 0.75187721 0.751964   0.75200049\n",
            " 0.75200913 0.75212741 0.75229502        nan 0.44162039 0.6366211\n",
            " 0.71526647 0.74211021 0.75031767 0.75149498 0.74979333 0.75055841\n",
            " 0.74957176 0.74963347 0.75083183 0.75092759 0.7512537  0.75111133\n",
            " 0.7511443  0.75128817 0.75129525 0.75147374 0.75158979 0.75165163\n",
            " 0.75174228 0.75180293 0.75181092 0.7518503  0.75191621 0.75195305\n",
            " 0.7519644  0.75196931 0.7520227  0.75201206        nan 0.57432682\n",
            " 0.68843072 0.72744185 0.74332492 0.75163279 0.75744177 0.75707318\n",
            " 0.75778041 0.75906861 0.75878084 0.75959558 0.75977756 0.75964037\n",
            " 0.76019404 0.7610827  0.76090473 0.76040188 0.76041047 0.75998803\n",
            " 0.75988326 0.7594421  0.75884913 0.7584093  0.75813311 0.75810602\n",
            " 0.75794573 0.7578297  0.75789877 0.7581875  0.75829578        nan\n",
            " 0.62489196 0.71378055 0.729368   0.72932519 0.73134374 0.73436371\n",
            " 0.73842467 0.7397051  0.74056015 0.74069808 0.74086735 0.74165548\n",
            " 0.74175698 0.74205098 0.74186444 0.74206849 0.74213708 0.74222957\n",
            " 0.74197801 0.74195017 0.74200673 0.74212848 0.74200838 0.74203948\n",
            " 0.74203481 0.7420924  0.74208212 0.74201884 0.7420872  0.74213708\n",
            "        nan 0.66304369 0.73607003 0.74500553 0.75051879 0.75141814\n",
            " 0.75181239 0.75310192 0.75452396 0.75544851 0.75587394 0.75578979\n",
            " 0.75581317 0.75599722 0.75595819 0.75600954 0.75594077 0.75591978\n",
            " 0.75584874 0.7558789  0.75591042 0.75591091 0.75591124 0.75591708\n",
            " 0.75593662 0.75593925 0.75591767 0.75590877 0.75590822 0.75591487\n",
            " 0.75591764        nan 0.68854968 0.74721404 0.74698177 0.74849407\n",
            " 0.74817144 0.74743661 0.74723152 0.74691333 0.74676555 0.7469226\n",
            " 0.74680626 0.74670386 0.74657767 0.74654775 0.74651293 0.74651041\n",
            " 0.74646598 0.74645522 0.74645912 0.74644729 0.74643325 0.74642176\n",
            " 0.74641897 0.74641965 0.74642037 0.74641783 0.74641874 0.74641644\n",
            " 0.74641524 0.74641535        nan 0.69839038 0.74591247 0.76274447\n",
            " 0.76487475 0.76552062 0.76390272 0.76568076 0.76577229 0.76442894\n",
            " 0.76204359 0.76107191 0.76018785 0.75952095 0.75866118 0.75864198\n",
            " 0.7583074  0.75799876 0.75763637 0.7574494  0.75718329 0.75745328\n",
            " 0.75702117 0.75681876 0.7563569  0.7558003  0.75578469 0.75562393\n",
            " 0.75562839 0.7554173  0.75558441        nan 0.7266868  0.73463225\n",
            " 0.73802906 0.74513205 0.74556224 0.7469647  0.74650622 0.74580983\n",
            " 0.74589333 0.74576875 0.74553702 0.7453829  0.74526924 0.74532044\n",
            " 0.74524746 0.74522081 0.74515817 0.74509105 0.74518492 0.74509774\n",
            " 0.74504098 0.74498108 0.74499064 0.7449775  0.74495697 0.74492394\n",
            " 0.74489033 0.74488306 0.74487541 0.74487227        nan 0.74021145\n",
            " 0.75883172 0.76209985 0.76334005 0.76376803 0.76382338 0.76381683\n",
            " 0.76366055 0.76368857 0.76361832 0.76364625 0.76357155 0.76353118\n",
            " 0.7634855  0.76346375 0.76343621 0.76341007 0.76339146 0.76338351\n",
            " 0.76337621 0.76337857 0.76337839 0.76337636 0.76337312 0.76337089\n",
            " 0.76337108 0.76337291 0.76337363 0.76337253 0.7633722         nan\n",
            " 0.74571047 0.74668845 0.74935718 0.74970523 0.74926151 0.74906092\n",
            " 0.74892571 0.74888652 0.74882492 0.74880427 0.74880015 0.7488084\n",
            " 0.74880045 0.74879522 0.74879776 0.74879558 0.74879556 0.74879518\n",
            " 0.74879529 0.74879532 0.74879514 0.74879482 0.74879466 0.74879453\n",
            " 0.74879452 0.74879448 0.74879444 0.74879443 0.74879443 0.74879442\n",
            "        nan 0.75164276 0.77371753 0.77642945 0.76798384 0.76549287\n",
            " 0.76489462 0.76385481 0.76385327 0.76395162 0.76320083 0.76258107\n",
            " 0.76272909 0.76241673 0.76176668 0.76158353 0.76147725 0.76125717\n",
            " 0.76100666 0.76075951 0.76062744 0.76037753 0.76037176 0.76045066\n",
            " 0.76039089 0.76028971 0.76018275 0.76015558 0.76005574 0.76001843\n",
            " 0.75991423        nan 0.74553423 0.75296184 0.75211068 0.7519718\n",
            " 0.75143081 0.75112    0.75068544 0.75043565 0.7505817  0.75047604\n",
            " 0.75049091 0.75052426 0.75054065 0.75045871 0.75039067 0.75037639\n",
            " 0.75036029 0.75033935 0.75032663 0.75031902 0.75031987 0.75032255\n",
            " 0.75030622 0.75030611 0.75030107 0.75030278 0.75030157 0.75029942\n",
            " 0.75029904 0.75029858        nan 0.75195689 0.75643669 0.75485059\n",
            " 0.75474466 0.75481942 0.75491543 0.75485914 0.75490701 0.75489583\n",
            " 0.75489304 0.75489078 0.7548878  0.75488683 0.75488395 0.75488327\n",
            " 0.75488331 0.75488275 0.75488225 0.7548823  0.75488219 0.75488218\n",
            " 0.75488222 0.7548822  0.75488218 0.75488218 0.75488218 0.75488217\n",
            " 0.75488217 0.75488217 0.75488217        nan 0.75094008 0.74964645\n",
            " 0.7495486  0.74944329 0.74950184 0.74948648 0.74948008 0.74947849\n",
            " 0.74947754 0.74947763 0.74947828 0.74947835 0.74947838 0.74947837\n",
            " 0.74947836 0.74947836 0.74947836 0.74947836 0.74947836 0.74947836\n",
            " 0.74947836 0.74947836 0.74947836 0.74947836 0.74947836 0.74947836\n",
            " 0.74947836 0.74947836 0.74947836 0.74947836]\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter Optimization with Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gradboost = GradientBoostingRegressor(random_state = 11)\n",
        "\n",
        "n_estimators = list(range(0, 601, 20))\n",
        "learning_rates = [0.02, 0.05, 0.1, 0.2]\n",
        "max_depths = [3, 4, 5, 6]\n",
        "\n",
        "params = {'n_estimators' : n_estimators, 'learning_rate' : learning_rates, 'max_depth' : max_depths}\n",
        "grid_gradboost = GridSearchCV(estimator = gradboost,\n",
        "                        param_grid = params,\n",
        "                        scoring = 'r2',\n",
        "                        cv = 5,\n",
        "                        n_jobs = -1)\n",
        "grid_gradboost.fit(X_train, y_train)\n",
        "\n",
        "# extract best estimator\n",
        "print(grid_gradboost.best_params_)\n",
        "\n",
        "# to test the best fit\n",
        "print(grid_gradboost.score(X_train, y_train))\n",
        "print(grid_gradboost.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjHVcao5rq5n",
        "outputId": "b538526e-e1e6-4b2c-f82c-577a6ff035f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training R2: 0.9873392600304229 RMSE: 1.3424006341639396 MAE: 0.9771624632040269\n",
            "Testing R2: 0.8489978451197223 RMSE: 4.666348762137309 MAE: 3.0689722166456868\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gradboost = GradientBoostingRegressor(learning_rate = 0.2, max_depth = 3, n_estimators = 60, random_state = 11)\n",
        "\n",
        "# training the model\n",
        "gradboost.fit(X_train, y_train)\n",
        "\n",
        "# predicting the results\n",
        "Y_train_gradboost = gradboost.predict(X_train)\n",
        "Y_test_gradboost = gradboost.predict(X_test)\n",
        "\n",
        "print(\"Training R2:\", r2_score(y_train, Y_train_gradboost), \"RMSE:\", np.sqrt(mean_squared_error(y_train, Y_train_gradboost)),\n",
        "      \"MAE:\", mean_absolute_error(y_train, Y_train_gradboost))\n",
        "print(\"Testing R2:\", r2_score(y_test, Y_test_gradboost), \"RMSE:\", np.sqrt(mean_squared_error(y_test, Y_test_gradboost)),\n",
        "      \"MAE:\", mean_absolute_error(y_test, Y_test_gradboost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w2q50_nrq5o",
        "outputId": "ab808a9d-d94a-42a0-cf4d-b3c8752d42d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Percentage Error (MAPE) - Training: inf%\n",
            "Mean Absolute Percentage Error (MAPE) - Testing: 8.9936%\n"
          ]
        }
      ],
      "source": [
        "# Calculate Mean Absolute Percentage Error (MAPE) for both training and testing sets\n",
        "mape_train = np.mean(np.abs((y_train - Y_train_gradboost) / y_train)) * 100\n",
        "mape_test = np.mean(np.abs((y_test - Y_test_gradboost) / y_test)) * 100\n",
        "print(f\"Mean Absolute Percentage Error (MAPE) - Training: {mape_train:.4f}%\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE) - Testing: {mape_test:.4f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbjWPlGJrq5o"
      },
      "outputs": [],
      "source": [
        "## convert your array into a dataframe\n",
        "df_pred = pd.DataFrame (Y_test_gradboost)\n",
        "df_pred.to_excel('Pred_gradboost_test.xlsx')\n",
        "\n",
        "\n",
        "## convert your array into a dataframe\n",
        "df_pred = pd.DataFrame (Y_train_gradboost)\n",
        "df_pred.to_excel('Pred_gradboost_train.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpRpvoIjrq5r",
        "outputId": "adee109a-dadd-4b75-9c8b-bffc511c86c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and scaler saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Save the model and scaler\n",
        "joblib.dump(gradboost, 'gradboost.joblib')  # Save the trained XGBoost model\n",
        "joblib.dump(scaler, 'scaler.joblib')  # Save the scaler\n",
        "\n",
        "print(\"Model and scaler saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEjOJGcwrq51",
        "outputId": "4eff12e6-d79e-46ab-a7a4-a46919a3cb94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
            "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import joblib\n",
        "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Matplotlib style\n",
        "plt.style.use('seaborn-ticks')\n",
        "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
        "\n",
        "# Feature names (customize as needed)\n",
        "featureName = [\n",
        "    r'$\\mathbf{Cement\\ (kg/m^3)}$',\n",
        "    r'$\\mathbf{Fly\\ ash\\ (kg/m^3)}$',\n",
        "    r'$\\mathbf{Silica\\ fume\\ (kg/m^3)}$',\n",
        "    r'$\\mathbf{Coarse\\ aggregate\\ (kg/m^3)}$',\n",
        "    r'$\\mathbf{Fine\\ aggregate\\ (kg/m^3)}$',\n",
        "    r'$\\mathbf{Water\\ (kg/m^3)}$',\n",
        "    r'$\\mathbf{Water\\ reducing\\ agent\\ (kg/m^3)}$',\n",
        "    r'$\\mathbf{Fiber\\ diameter\\ (mm)}$',\n",
        "    r'$\\mathbf{Fiber\\ length\\ (mm)}$',\n",
        "    r'$\\mathbf{Fiber\\ content\\ (\\%)}$'\n",
        "]\n",
        "\n",
        "# Initialize the Tkinter window\n",
        "root = tk.Tk()\n",
        "root.title(\"GUI\")\n",
        "root.geometry(\"950x700\")\n",
        "\n",
        "# Create canvas for displaying the SHAP plot\n",
        "frame_canvas = tk.Canvas(root)\n",
        "frame_canvas.pack(fill=tk.BOTH, expand=True)\n",
        "\n",
        "# Load model and scaler\n",
        "try:\n",
        "    gradboost = joblib.load('gradboost.joblib')\n",
        "    scaler = joblib.load('scaler.joblib')\n",
        "except Exception as e:\n",
        "    messagebox.showerror(\"Error\", f\"Error loading model or scaler: {e}\")\n",
        "    root.destroy()\n",
        "\n",
        "# Load data for prediction and SHAP calculation\n",
        "def load_data_and_plot():\n",
        "    try:\n",
        "        # Load data from Excel file\n",
        "        df = pd.read_excel(\"BFRC_CS.xlsx\")\n",
        "\n",
        "        # Assuming the data includes the relevant features and the target variable\n",
        "        X = df.iloc[:, :-1]  # Features (excluding target variable)\n",
        "        y = df.iloc[:, -1]  # Target variable (Concrete Compressive Strength)\n",
        "\n",
        "        # Standardize the features\n",
        "        X_scaled = scaler.transform(X)\n",
        "\n",
        "        # Calculate SHAP values\n",
        "        explainer = shap.Explainer(gradboost)\n",
        "        shap_values = explainer(X_scaled)\n",
        "\n",
        "        # Create a SHAP summary plot (Feature importance)\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        shap.summary_plot(shap_values, X_scaled, feature_names=featureName, plot_type=\"bar\", ax=ax)\n",
        "\n",
        "        # Display plot in Tkinter window\n",
        "        canvas = FigureCanvasTkAgg(fig, master=frame_canvas)\n",
        "        canvas.draw()\n",
        "        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        messagebox.showerror(\"Error\", f\"Error loading data or generating SHAP plot: {e}\")\n",
        "\n",
        "# Load data and plot SHAP feature importance\n",
        "load_data_and_plot()\n",
        "\n",
        "# Function to create labels on the canvas\n",
        "def create_label(text, font, fg, bg, x, y):\n",
        "    label = tk.Label(root, text=text, font=font, fg=fg, bg=bg)\n",
        "    frame_canvas.create_window(x, y, anchor=\"w\", window=label)  # Now canvas can use create_window\n",
        "    return label\n",
        "\n",
        "# GUI Titles\n",
        "label_inputdefinetitle2 = create_label('GUI model for Predicting Compressive Strength of BFRC',\n",
        "                                      ('Comic Sans MS', 18, 'bold', 'underline'), '#0000FF', '#FFFF00', 20, 30)\n",
        "label_inputdefinetitle3 = create_label('Developed by: Abul KASHEM,Pobithra Das,Sourov Paul,Kaffayatullah Khan,Abdulrahman Fahad Al Fuhaid, Md Arifuzzaman',\n",
        "                                      ('Comic Sans MS', 14, 'bold'), '#C00000', '#FFFFFF', 20, 70)\n",
        "label_inputdefinetitle = create_label('Input Parameters',\n",
        "                                      ('Comic Sans MS', 16, 'bold'), '#000000', '#FFFFFF', 50, 120)\n",
        "\n",
        "# Parameter Definitions (left)\n",
        "param_labels = [\n",
        "    'X1: Cement (kg/m³)',\n",
        "    'X2: Fly Ash (kg/m³)',\n",
        "    'X3: Silica Fume (kg/m³)',\n",
        "    'X4: Coarse Aggregate (kg/m³)',\n",
        "    'X5: Fine Aggregate (kg/m³)',\n",
        "    'X6: Water (kg/m³)',\n",
        "    'X7: Water Reducing Agent (kg/m³)',\n",
        "    'X8: Fiber Content (%)',\n",
        "    'X9: Fiber Diameter (mm)',\n",
        "    'X10: Fiber Length (mm)'\n",
        "]\n",
        "\n",
        "# Draw parameter labels on left side\n",
        "for i, text in enumerate(param_labels, start=1):\n",
        "    create_label(text, ('Comic Sans MS', 14), '#00008B', '#FFFFFF', 50, 180 + i*40)\n",
        "\n",
        "# Input title (right)\n",
        "label_inputs = create_label('Inputs', ('Comic Sans MS', 16, 'bold'), '#000000', '#FFFFFF', 620, 180)\n",
        "\n",
        "# Input Fields (right)\n",
        "entry_fields = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8','X9','X10']\n",
        "entries = {}\n",
        "for i, field in enumerate(entry_fields, start=1):\n",
        "    create_label(f'{field} = ', ('Comic Sans MS', 14, 'bold'), '#006600', '#FFFFFF', 650, 180 + i*40)\n",
        "    entry = tk.Entry(root, font=('Comic Sans MS', 14, 'bold'), bg='#F0F0F0',\n",
        "                     highlightbackground='#000000', highlightthickness=1, bd=0, width=20)\n",
        "    frame_canvas.create_window(830, 180 + i*40, window=entry)\n",
        "    entries[field] = entry\n",
        "\n",
        "# Output Section (placed much lower)\n",
        "label_output = create_label('Output:', ('Comic Sans MS', 16, 'bold'), '#000000', '#FFFFFF', 50, 650)\n",
        "label_result = create_label('Compressive strength (MPa)',\n",
        "                            ('Comic Sans MS', 16, 'bold'), '#C00000', '#FFFFFF', 200, 650)\n",
        "\n",
        "# Optional: Set proper window height\n",
        "root.geometry(\"1050x800\")  # Adjust based on your needs\n",
        "\n",
        "\n",
        "# Predict button command function\n",
        "def predict():\n",
        "    # Collect input data\n",
        "    input_values = []\n",
        "    for field in entry_fields:\n",
        "        try:\n",
        "            value = float(entries[field].get())\n",
        "            if value <= 0:\n",
        "                raise ValueError(\"Value must be positive.\")\n",
        "            input_values.append(value)\n",
        "        except ValueError as e:\n",
        "            messagebox.showerror(\"Error\", f\"Invalid input for {field}. Please enter a positive numeric value.\")\n",
        "            return\n",
        "\n",
        "    input_data = np.array([input_values])\n",
        "    try:\n",
        "        # Predict using the model\n",
        "        input_scaled = scaler.transform(input_data)\n",
        "        prediction = xgboost_model.predict(input_scaled)\n",
        "        label_result['text'] = f'CS = {prediction[0]:.4f} (MPa)'\n",
        "    except Exception as e:\n",
        "        messagebox.showerror(\"Error\", f\"An error occurred during prediction: {e}\")\n",
        "\n",
        "# Predict button\n",
        "predict_button = tk.Button(root, text='Calculate', font=('Comic Sans MS', 16), command=predict, fg='#FFFFFF', bg='dark blue')\n",
        "frame_canvas.create_window(750, 650, window=predict_button)\n",
        "\n",
        "# Run the Tkinter event loop\n",
        "root.mainloop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4KA_K6Frq52"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}